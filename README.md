## Voice Call Translator

Always wanted to talk to your uncle who lives at the South Pole but neither of you learned the
other's language? Don't worry, with Voice Call Translator the problem is solved, or partially
solved.

# What is Voice Call Translator or VCT?

VCT is a P2P calling application with instant call translation. What it is based on:

- Firebase for Signaling and live chat messages
  - Firebase [Auth](https://firebase.google.com/docs/auth) for SignUp and authentication
  - [Realtime Database](https://firebase.google.com/docs/database) for User interactions
- [WebRTC](https://webrtc.org/) for establishing P2P communication (provided by GetStream library)
- STUN and TURN servers to facilitate communication through NAT (requires specific credentials)
- Three different [models](https://platform.openai.com/docs/models/model-endpoint-compatibility)
  from OpenAI for the magic:
  - Whisper for the transcriptions ([whisper-1](https://platform.openai.com/docs/models/whisper))
  - ChatGPT for
    translations ([gpt-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo))
  - TTS for speeches ([tts-1](https://platform.openai.com/docs/models/tts))

![VCT](readme/vct-frame.png)

## Architecture

- Single Activity approach. SignUp, Make calls and Receive calls, as simple as that.
- MVVM managing one VM per main feature.
- Compose for Views and Navigation.
- DataStore for User preferences.
- Hilt, Coroutines, nothing special!
- There is a background Service that handles Notifications and pretends to allow receiving calls in
  the background, but it does not work properly. Besides the implementation using the Firebase
  connection is not the most efficient and can drain the device battery.

# Design

Simple design, basic components with virtually no customization. No frills, straight to the point
using the components already generated by the Material library.

## Flows

- Permissions screen ()
- SignUp and Login. Splash screen to manage auto-login, Language and Theme initializations.
- Contact list. To simplify the POC, all accounts registered in Firebase are shared among all other
  users as contacts available to be called. If you are going to call only your uncle, this will not
  be a problem.
- Settings menu to update Language, Theme and account actions.
- Call screen with an embedded chat history to read the transcriptions for both Users.

![VCT](readme/flow-call.png)

## How to play

- Clone the repo
- Create a Firebase project, setup Auth to allow users to registration and the Realtime Database.
  Then download the google-services.json file to add it on the project root.
- [VctApiKeys](https://github.com/slopezjur/VoiceCallTranslator/blob/main/app/src/main/kotlin/com/sergiolopez/voicecalltranslator/VctApiKeys.kt)
  - Get TURN credentials. There are many free and paid options. I've been
    using [Metered](https://www.metered.ca/stun-turn). They offer a free plan with reasonable
    monthly limit for your personal usage. This is not a recommendation, use this option at your own
    risk.
  - Get the OpenAI [api key](https://platform.openai.com/api-keys) for the magic. There is no free
    plan to use OpenAI API.

# Bonus

It is possible to extract and save the audios generated by the user as well as those received by
OpenAI.
First it is necessary to comment out the deleteFile function within the MagicAudioProcessor class to
ensure that the audios generated by the user during the conversation are not deleted after
fulfilling their function. To create the audios by the OpenAI API it is only necessary to uncomment
the createWavFileFromByteArray method.
Finally, if we want to have full control over the temporary folder where the audios are stored, it
is necessary to comment out the cleanAudioRecords() method in VoiceCallTranslatorActivity. With this
we make sure that the folder is not cleaned at each startup.

To extract the audios we only need to use ADB. Example command:
.\adb -s adb-example-device pull '
/storage/emulated/0/Android/data/com.sergiolopez.voicecalltranslator/files/Recordings' 'C:
\Users\exampleName\VCT\Audios\Device1

## Known problems

- Whisper may not have been the best choice for handling transcriptions between 1 and 3 seconds but
  it is the option finally implemented. This model has a serious problem with silences that is
  complex to handle. Currently there is an audio control implemented to reduce these silences but it
  doesn't work perfectly, that's why Whisper will return invented transcriptions if you don't sile
  the microphone as if it were a Walkie-talkie. Currently the application works with the mic open by
  default, so you can expect some of these hallucinations from the model.
- Background Service is not working properly. It is being killed by the OS very ofter or not able to
  properly get the Firebase call status.
- There is no correct handling of the Activity and its screens to keep the instance open in the
  foreground. It is possible to achieve unexpected behaviors by simply playing with the flows.

## Purpose or Reason to exist

This app has been built to demonstrate that anyone can use existing tools to perform real-time
translations during phone calls between people who do not speak the same language.

This project is not ready for production deployment nor is it intended to be a best practice guide
for building a real-time calling application. As this is a POC, the ultimate goal was to build a
complete and functional application so there may be several tradeoffs and concessions throughout the
code that will or will not be improved over time.